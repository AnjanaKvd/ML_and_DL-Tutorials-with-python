{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/codebasics/deep-learning-keras-tf-tutorial/master/13_dropout_layer/sonar_dataset.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   0  \n",
       "1  0.0052  0.0044   0  \n",
       "2  0.0095  0.0078   0  \n",
       "3  0.0040  0.0117   0  \n",
       "4  0.0107  0.0094   0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[60].replace({'M':1, 'R':0}, inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((166, 60), (42, 60), (166,), (42,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df1.drop(60, axis=1)\n",
    "y = df1[60]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model without dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 0.6860 - accuracy: 0.5241 \n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5783\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.7048\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7530\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.5809 - accuracy: 0.7349\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7651\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7831\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7892\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7771\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7831\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.7952\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8253\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8313\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8313\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8494\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8494\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8614\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3070 - accuracy: 0.8614\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8434\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8855\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8735\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.9036\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8614\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.8795\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.9036\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9157\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.9337\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9337\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9096\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9639\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9398\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9337\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.9518\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1560 - accuracy: 0.9578\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9639\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9578\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9578\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9578\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9518\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9759\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9819\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0920 - accuracy: 0.9819\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0892 - accuracy: 0.9759\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9880\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9880\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9759\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9880\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9880\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9699\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9940\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9880\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.9940\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9940\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9940\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 0.9940\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227fa49a950>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_shape=(60,), activation= 'relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7359469532966614, 0.8571428656578064]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we got 1 score on training samples but .85 score on test samples. So it's look like our model was overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207    1\n",
       "206    1\n",
       "158    1\n",
       "131    1\n",
       "146    1\n",
       "175    1\n",
       "72     0\n",
       "15     0\n",
       "196    1\n",
       "195    1\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79        12\n",
      "           1       0.96      0.83      0.89        30\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.82      0.88      0.84        42\n",
      "weighted avg       0.88      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(data=cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 0.7025 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6918 - accuracy: 0.5482\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5663\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6510 - accuracy: 0.6627\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.6506\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6521 - accuracy: 0.6265\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6506\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.6048 - accuracy: 0.6867\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6566\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6747\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5557 - accuracy: 0.7048\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7771\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7590\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7711\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7289\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7711\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7590\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7590\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8313\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8434\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7952\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.7952\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3832 - accuracy: 0.8253\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8373\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8554\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.8916\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8313\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3276 - accuracy: 0.8253\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8795\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8795\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3122 - accuracy: 0.8675\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8675\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.8916\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.8916\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2589 - accuracy: 0.8855\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2692 - accuracy: 0.8916\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2371 - accuracy: 0.8976\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2435 - accuracy: 0.8976\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2557 - accuracy: 0.9036\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.9036\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2369 - accuracy: 0.9217\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9096\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2023 - accuracy: 0.9277\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.2145 - accuracy: 0.9277\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.1968 - accuracy: 0.9217\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9458\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9217\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9337\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9337\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9337\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9398\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9277\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9578\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9398\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9337\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9458\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1195 - accuracy: 0.9518\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9699\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1532 - accuracy: 0.9458\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9578\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9217\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9639\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9759\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9639\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9639\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9880\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9639\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9337\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9819\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9578\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9639\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9639\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 0.9699\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0714 - accuracy: 0.9880\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9699\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9699\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9578\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9819\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9699\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9759\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9639\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.9458\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9518\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9458\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9940\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9699\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9578\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0706 - accuracy: 0.9819\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9639\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9819\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9940\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9819\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9880\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9880\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9940\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9819\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0733 - accuracy: 0.9699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ffde7640>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_shape=(60,), activation= 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(15, activation='relu'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "modeld.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "modeld.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3503682613372803, 0.9047619104385376]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeld.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look we got 90% of score with dropout layers. It's good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79        12\n",
      "           1       0.96      0.83      0.89        30\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.82      0.88      0.84        42\n",
      "weighted avg       0.88      0.86      0.86        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(data=cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6620d693ca7c7a10075057bff34b8dd87106bc125da937751c4c9f4d856e6699"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
